# Openstack tích hợp CEPH

## Mô hình triển khai
```sh
                                                         | eth0
                            +----------------------------+----------------------------+
                            |                            |                            |
                            |10.0.0.51                   |10.0.0.52                   |10.0.0.53 
                +-----------+-----------+    +-----------+-----------+    +-----------+-----------+
                |        [node01]       |    |        [node02]       |    |        [node03]       |
                |     Object Storage    +----+     Object Storage    +----+     Object Storage    |
                |     Monitor Daemon    |    |                       |    |                       |
                |     Manager Daemon    |    |                       |    |                       |    
                |     Openstack AIO     |    |                       |    |                       |    
                |                       |    |                       |    |                       |
                +-----------+-----------+    +-----------------------+    +-----------------------+
                        eth1|
```
Đối với OpenStack có 3 thành phần có thể kết nối được với Ceph. 

- Images: OpenStack Glance quản lý các image cho các VM, lưu trữ các images dưới dạng nhị phân. 
- Volumes: Các Block Devices được sử dụng để boot các VM hoặc là các ổ đĩa đính kèm thêm cho VM.
- Guest Disk: Mặc định khi tạo VM từ images thì disk của nó được lưu trữ dưới dạng filesystems. 


## 1.Tạo pool trên CEPH

```sh
root@quynv:~# ceph osd pool create volumes 32 32
root@quynv:~# ceph osd pool create vms 32 32
root@quynv:~# ceph osd pool create images 32 32
```

- Khởi tạo trước khi sử dụng pool

```sh
root@quynv:~# rbd pool init volumes
root@quynv:~# rbd pool init vms
root@quynv:~# rbd pool init images
root@quynv:~# rbd pool init backups
```
## 2.Cấu hình CEPH làm backend cho Glance  

- Tạo key glance

```sh
root@quynv:~# ceph auth get-or-create client.glance mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=images' > ceph.client.glance.keyring
root@quynv:~# ceph auth get-or-create client.glance | tee /etc/ceph/ceph.client.glance.keyring
```

- Set quyền cho key

```sh
root@quynv:~# chown glance:glance /etc/ceph/ceph.client.glance.keyring
root@quynv:~# chmod 0640 /etc/ceph/ceph.client.glance.keyring
```
- Thêm cấu hình file /etc/glance/glance-api.conf

```sh
[glance_store]
default_store = rbd
stores = file,http,rbd
rbd_store_pool = images
rbd_store_user = glance
rbd_store_ceph_conf = /etc/ceph/ceph.conf
rbd_store_chunk_size = 8
```
- Restart dịch vụ glance

```sh
systemctl restart glance-*
```

- Tạo images và kiểm tra lưu trữ trên CEPH

```sh
root@quynv:~# glance image-create --name "cirros" \
>   --file cirros-0.4.0-x86_64-disk.img \
>   --disk-format qcow2 --container-format bare \
>   --visibility=public
+------------------+----------------------------------------------------------------------------------+
| Property         | Value                                                                            |
+------------------+----------------------------------------------------------------------------------+
| checksum         | 443b7623e27ecf03dc9e01ee93f67afe                                                 |
| container_format | bare                                                                             |
| created_at       | 2022-01-13T07:04:32Z                                                             |
| disk_format      | qcow2                                                                            |
| id               | ad365e84-752d-489a-b355-74a154b3691b                                             |
| min_disk         | 0                                                                                |
| min_ram          | 0                                                                                |
| name             | cirros                                                                           |
| os_hash_algo     | sha512                                                                           |
| os_hash_value    | 6513f21e44aa3da349f248188a44bc304a3653a04122d8fb4535423c8e1d14cd6a153f735bb0982e |
|                  | 2161b5b5186106570c17a9e58b64dd39390617cd5a350f78                                 |
| os_hidden        | False                                                                            |
| owner            | 031b92baee26462c938d05dfac4a8834                                                 |
| protected        | False                                                                            |
| size             | 12716032                                                                         |
| status           | active                                                                           |
| tags             | []                                                                               |
| updated_at       | 2022-01-13T07:04:33Z                                                             |
| virtual_size     | 46137344                                                                         |
| visibility       | public                                                                           |
+------------------+----------------------------------------------------------------------------------+

root@quynv:~# rbd -p images ls -l
NAME                                       SIZE     PARENT  FMT  PROT  LOCK
ad365e84-752d-489a-b355-74a154b3691b        12 MiB            2
b597ed5e-4f96-4295-9434-c6b69a634516@snap  1.2 GiB            2  yes

```

## 3.Cấu hình CEPH làm backend cho Cinder

- Tạo và di chuyển key cinder

```sh
root@quynv:~# ceph auth get-or-create client.cinder mon 'allow r, allow command "osd blacklist", allow command "blacklistop"' osd 'allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rwx pool=images' > ceph.client.cinder.keyring
root@quynv:~# ceph auth get-or-create client.cinder | tee /etc/ceph/ceph.client.cinder.keyring
root@quynv:~# ceph auth get-key client.cinder | tee /root/client.cinder
```

- Set quyền cho key

```sh
root@quynv:~# chown cinder:cinder /etc/ceph/ceph.client.cinder*
root@quynv:~# chmod 0640 /etc/ceph/ceph.client.cinder*
```

- Khởi tạo 1 uuid mới cho Cinder
```sh
root@quynv:~# uuidgen
f81d4a93-3f0a-41d7-bccc-ec48c55df319
```

- Tạo file xml cho phép Ceph RBD (Rados Block Device) xác thực với libvirt thông qua uuid vừa tạo
```sh
root@quynv:~# cat > ceph.xml <<EOF
<secret ephemeral='no' private='no'>
<uuid>f81d4a93-3f0a-41d7-bccc-ec48c55df319</uuid>
<usage type='ceph'>
	<name>client.cinder secret</name>
        <name>client.nova secret</name>
</usage>
</secret>
EOF
root@quynv:~# virsh secret-define --file ceph.xml
Secret f81d4a93-3f0a-41d7-bccc-ec48c55df319 created
```
- Gán giá trị của client.cinder cho uuid

```sh
root@quynv:~# virsh secret-set-value --secret f81d4a93-3f0a-41d7-bccc-ec48c55df319 --base64 $(cat /root/client.cinder)
Secret value set
```
- Thêm cấu hinh /etc/cinder/cinder.conf

```sh
[DEFAULT]
...
enabled_backends = ceph
glance_api_version = 2

[ceph]
volume_driver = cinder.volume.drivers.rbd.RBDDriver
volume_backend_name = ceph
rbd_pool = volumes
rbd_ceph_conf = /etc/ceph/ceph.conf
rbd_flatten_volume_from_snapshot = false
rbd_max_clone_depth = 5
rbd_store_chunk_size = 4
rados_connect_timeout = -1
rbd_user = cinder
rbd_secret_uuid = f81d4a93-3f0a-41d7-bccc-ec48c55df319
```

- Restart dịch vụ cinder

```sh
root@quynv:~# systemctl restart cinder-api cinder-volume cinder-scheduler
```
- Tạo volume type
```sh
root@quynv:~#root@quynv:~# cinder type-create ceph
root@quynv:~# cinder type-key ceph set volume_backend_name=ceph
```
- Khởi tạo volume và kiểm tra trên CEPH


```sh
root@quynv:~# openstack volume create --size 1 testceph
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2022-01-13T08:46:33.000000           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | 0f692716-fd1c-4da7-a6a9-bcd6e2511d76 |
| migration_status    | None                                 |
| multiattach         | False                                |
| name                | testceph                             |
| properties          |                                      |
| replication_status  | None                                 |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | __DEFAULT__                          |
| updated_at          | None                                 |
| user_id             | 7bc4d6264fd84f0cb9bf7f8ce25388e4     |
+---------------------+--------------------------------------+
root@quynv:~# rbd -p volumes ls -l
NAME                                         SIZE   PARENT  FMT  PROT  LOCK
volume-0f692716-fd1c-4da7-a6a9-bcd6e2511d76  1 GiB            2

```
## 4.Cấu hình CEPH làm backend cho Nova

- Tạo và di chuyển keyring cho nova
```sh
root@quynv:~# ceph auth get-or-create client.nova mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=vms, allow rx pool=images' -o /etc/ceph/ceph.client.nova.keyring 
root@quynv:~# ceph auth get-or-create client.nova | tee /etc/ceph/ceph.client.nova.keyring 
root@quynv:~# ceph auth get-key client.nova | tee /root/client.nova
```

- Set quyền

```sh
root@quynv:~# chgrp nova /etc/ceph/ceph.client.nova.keyring
root@quynv:~# chmod 0640 /etc/ceph/ceph.client.nova.keyring
```
- Gán giá trị của client.nova cho uuid tạo ở trước đó.

```sh
root@quynv:~# virsh secret-set-value --secret f81d4a93-3f0a-41d7-bccc-ec48c55df319 --base64 $(cat /root/client.nova)
Secret value set
```

- Thêm cấu hình libvirt trên /etc/nova/nova.conf

```sh
[libvirt]
images_rbd_pool=vms
images_type=rbd
rbd_secret_uuid=f81d4a93-3f0a-41d7-bccc-ec48c55df319
rbd_user=nova
images_rbd_ceph_conf = /etc/ceph/ceph.conf
```

- Restart nova-compute

```sh
root@quynv:~# systemctl restart nova-compute
```

- Boot VM và kiểm tra trên CEPH
```sh
root@quynv:~# nova boot --flavor cirros256 --image 396f64b1-4672-481b-bc32-16a8c4c3d962 --security-groups default --nic net-name=public node02
+--------------------------------------+-----------------------------------------------+
| Property                             | Value                                         |
+--------------------------------------+-----------------------------------------------+
| OS-DCF:diskConfig                    | MANUAL                                        |
| OS-EXT-AZ:availability_zone          |                                               |
| OS-EXT-SRV-ATTR:host                 | -                                             |
| OS-EXT-SRV-ATTR:hostname             | node02                                        |
| OS-EXT-SRV-ATTR:hypervisor_hostname  | -                                             |
| OS-EXT-SRV-ATTR:instance_name        |                                               |
| OS-EXT-SRV-ATTR:kernel_id            |                                               |
| OS-EXT-SRV-ATTR:launch_index         | 0                                             |
| OS-EXT-SRV-ATTR:ramdisk_id           |                                               |
| OS-EXT-SRV-ATTR:reservation_id       | r-x0xstoly                                    |
| OS-EXT-SRV-ATTR:root_device_name     | -                                             |
| OS-EXT-STS:power_state               | 0                                             |
| OS-EXT-STS:task_state                | scheduling                                    |
| OS-EXT-STS:vm_state                  | building                                      |
| OS-SRV-USG:launched_at               | -                                             |
| OS-SRV-USG:terminated_at             | -                                             |
| accessIPv4                           |                                               |
| accessIPv6                           |                                               |
| adminPass                            | 7PvrtdSSeSHE                                  |
| config_drive                         |                                               |
| created                              | 2022-01-13T13:04:26Z                          |
| description                          | -                                             |
| flavor:disk                          | 1                                             |
| flavor:ephemeral                     | 0                                             |
| flavor:extra_specs                   | {}                                            |
| flavor:original_name                 | cirros256                                     |
| flavor:ram                           | 256                                           |
| flavor:swap                          | 0                                             |
| flavor:vcpus                         | 1                                             |
| hostId                               |                                               |
| host_status                          |                                               |
| id                                   | 84d3c0b6-abd9-4105-b0a1-9ab0e00e6cd1          |
| image                                | cirros (396f64b1-4672-481b-bc32-16a8c4c3d962) |
| key_name                             | -                                             |
| locked                               | False                                         |
| locked_reason                        | -                                             |
| metadata                             | {}                                            |
| name                                 | node02                                        |
| os-extended-volumes:volumes_attached | []                                            |
| progress                             | 0                                             |
| security_groups                      | default                                       |
| server_groups                        | []                                            |
| status                               | BUILD                                         |
| tags                                 | []                                            |
| tenant_id                            | e7eb5968d08a4bd68193ce335190fb5c              |
| trusted_image_certificates           | -                                             |
| updated                              | 2022-01-13T13:04:26Z                          |
| user_id                              | 44494caa134d4fc795f14a73909ce707              |
+--------------------------------------+-----------------------------------------------+
root@quynv:~# rbd -p vms ls
84d3c0b6-abd9-4105-b0a1-9ab0e00e6cd1_disk
root@quynv:~# rbd -p vms info 84d3c0b6-abd9-4105-b0a1-9ab0e00e6cd1_disk
rbd image '84d3c0b6-abd9-4105-b0a1-9ab0e00e6cd1_disk':
        size 1 GiB in 256 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: 6074c728cb31
        block_name_prefix: rbd_data.6074c728cb31
        format: 2
        features: layering, exclusive-lock, object-map, fast-diff, deep-flatten
        op_features:
        flags:
        create_timestamp: Thu Jan 13 13:04:55 2022
        access_timestamp: Thu Jan 13 13:04:55 2022
        modify_timestamp: Thu Jan 13 13:04:55 2022
```
